#!/usr/bin/env python3
"""
LLM Component Generator - Generates real component implementations using LLM
No templates, no placeholders, no fallbacks - only real logic generation
"""
import os
import json
from typing import Dict, Any, Optional, Union
from dotenv import load_dotenv

# Multi-provider LLM abstraction imports
from autocoder_cc.llm_providers.multi_provider_manager import MultiProviderManager
from autocoder_cc.llm_providers.openai_provider import OpenAIProvider
from autocoder_cc.llm_providers.anthropic_provider import AnthropicProvider
from autocoder_cc.llm_providers.gemini_provider import GeminiProvider
from autocoder_cc.llm_providers.base_provider import LLMRequest

from autocoder_cc.core.config import settings
from autocoder_cc.error_handling import ConsistentErrorHandler
from autocoder_cc.observability.structured_logging import get_logger
from autocoder_cc.observability.metrics import get_metrics_collector
import time
import random
from enum import Enum
from dataclasses import dataclass

load_dotenv()


class ErrorType(Enum):
    """Types of errors that can occur during LLM generation"""
    API_ERROR = "api_error"           # Network, rate limits, timeouts
    VALIDATION_ERROR = "validation_error"  # Content validation failures
    SYNTAX_ERROR = "syntax_error"     # Invalid Python syntax
    PATTERN_ERROR = "pattern_error"   # Missing required patterns


@dataclass
class RetryStrategy:
    """Strategy for handling different types of errors during LLM generation"""
    max_retries: int
    base_delay: float
    backoff_multiplier: float
    max_delay: float
    
    def get_delay(self, attempt: int, error_type: ErrorType) -> float:
        """Calculate delay for given attempt and error type"""
        if error_type == ErrorType.VALIDATION_ERROR:
            # Shorter delays for content validation errors since they're not network-related
            base = min(self.base_delay * 0.5, 1.0)
        else:
            # Standard delays for API errors
            base = self.base_delay
            
        delay = base * (self.backoff_multiplier ** attempt)
        jitter = random.uniform(0, 0.1 * delay)
        
        return min(delay + jitter, self.max_delay)
    
    def should_retry(self, error_type: ErrorType, attempt: int) -> bool:
        """Determine if we should retry based on error type and attempt count"""
        if attempt >= self.max_retries:
            return False
            
        # Always retry validation errors since they can be fixed with better prompts
        if error_type == ErrorType.VALIDATION_ERROR:
            return True
            
        # Retry API errors with standard logic
        if error_type == ErrorType.API_ERROR:
            return True
            
        # Retry syntax errors - might be fixable
        if error_type == ErrorType.SYNTAX_ERROR:
            return True
            
        # Retry pattern errors - fixable with better prompts
        if error_type == ErrorType.PATTERN_ERROR:
            return True
            
        return False


class ComponentGenerationError(Exception):
    """Raised when component generation fails - no fallbacks available"""
    pass


class LLMComponentGenerator:
    """
    Generates component implementations using LLM with fail-hard principles
    
    Key Principles:
    - ALL component logic MUST be generated by LLM
    - NO hardcoded templates or placeholders
    - NO fallback modes or mock implementations
    - Fail hard if LLM is unavailable
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize multi-provider LLM system - fail hard if not configured"""
        
        # Initialize structured logger
        self.logger = get_logger(__name__, component="llm_component_generator")
        
        # Initialize metrics collector
        self.metrics = get_metrics_collector("llm_component_generator")
        
        # Use provided config or default from settings
        if config is None:
            config = {
                "llm_providers": {
                    "primary_provider": "openai",  # Use OpenAI for o3 model support
                    "fallback_providers": ["gemini", "anthropic"],
                    "max_retries": 3
                },
                "openai_model": "o3-mini"  # Use o3-mini model for better reasoning
            }
        
        # Initialize multi-provider system
        provider_config = config.get("llm_providers", {
            "primary_provider": "openai",  # Use OpenAI for o3 model support
            "fallback_providers": ["gemini", "anthropic"],
            "max_retries": 3
        })
        
        self.multi_provider = MultiProviderManager(provider_config)
        
        # Register providers based on configuration
        primary_provider = provider_config["primary_provider"]
        fallback_providers = provider_config.get("fallback_providers", [])
        all_providers = [primary_provider] + fallback_providers
        
        if "openai" in all_providers:
            openai_config = {
                "api_key": config.get("openai_api_key") or os.getenv("OPENAI_API_KEY"),
                "default_model": config.get("openai_model", "o3-mini")  # Use o3-mini by default
            }
            if openai_config["api_key"]:
                openai_provider = OpenAIProvider(openai_config)
                self.multi_provider.registry.register_provider(openai_provider)
                self.logger.info("Registered OpenAI provider")
        
        if "anthropic" in all_providers:
            anthropic_config = {
                "api_key": config.get("anthropic_api_key") or os.getenv("ANTHROPIC_API_KEY"),
                "default_model": config.get("anthropic_model", "claude-3-5-sonnet-20241022")
            }
            if anthropic_config["api_key"]:
                anthropic_provider = AnthropicProvider(anthropic_config)
                self.multi_provider.registry.register_provider(anthropic_provider)
                self.logger.info("Registered Anthropic provider")
        
        if "gemini" in all_providers:
            gemini_config = {
                "api_key": config.get("gemini_api_key") or os.getenv("GEMINI_API_KEY"),
                "default_model": config.get("gemini_model", "gemini-2.5-flash")
            }
            if gemini_config["api_key"]:
                gemini_provider = GeminiProvider(gemini_config)
                self.multi_provider.registry.register_provider(gemini_provider)
                self.logger.info("Registered Gemini provider")
        
        # Verify at least one provider is registered
        if not self.multi_provider.registry.list_providers():
            raise ComponentGenerationError(
                "No LLM providers available. Set GEMINI_API_KEY, OPENAI_API_KEY and/or ANTHROPIC_API_KEY. "
                "Multi-provider system requires at least one configured provider."
            )
        
        self.logger.info("Multi-provider LLM system initialized", {
            "providers": self.multi_provider.registry.list_providers(),
            "primary_provider": provider_config["primary_provider"]
        })
        
        # Error handling configuration
        self.max_retries = settings.MAX_RETRIES
        self.retry_delay = settings.RETRY_DELAY
        self.circuit_breaker_failures = 0
        self.circuit_breaker_threshold = 5
        self.circuit_breaker_timeout = 60  # seconds
        
        # Initialize RetryStrategy for different error types
        self.retry_strategy = RetryStrategy(
            max_retries=self.max_retries,
            base_delay=self.retry_delay,
            backoff_multiplier=2.0,
            max_delay=30.0
        )
        
        # Setup consistent error handler
        self.error_handler = ConsistentErrorHandler("LLMComponentGenerator")
    
    async def generate_component_implementation_enhanced(
        self, 
        component_type: str,
        component_name: str,
        component_description: str,
        component_config: Dict[str, Any],
        class_name: str,
        system_context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Generate component implementation with enhanced context-aware prompting
        
        Args:
            component_type: Type of component (Source, Transformer, etc.)
            component_name: Name of the component
            component_description: Description of component functionality
            component_config: Component configuration
            class_name: Generated class name
            system_context: System-wide context for enhanced generation
            
        Returns:
            Complete Python implementation with system-aware business logic
            
        Raises:
            ComponentGenerationError: If generation fails
        """
        
        # Build enhanced context-aware prompt
        system_prompt = self._get_system_prompt(component_type)
        
        # Use enhanced prompting if system context is available
        if system_context:
            user_prompt = self._build_context_aware_prompt(
                component_type, component_name, component_description, 
                component_config, class_name, system_context
            )
        else:
            # Fallback to original prompting for backward compatibility
            user_prompt = self._build_component_prompt(
                component_type, component_name, component_description, 
                component_config, class_name
            )
        
        return await self._generate_with_retry_logic(
            system_prompt, user_prompt, component_type, component_name, class_name
        )

    async def generate_component_implementation(
        self, 
        component_type: str,
        component_name: str,
        component_description: str,
        component_config: Dict[str, Any],
        class_name: str
    ) -> str:
        """
        Generate complete component implementation using LLM
        
        Args:
            component_type: Type of component (Source, Transformer, etc.)
            component_name: Name of the component
            component_description: Description of component functionality
            component_config: Component configuration
            class_name: Generated class name
            
        Returns:
            Complete Python implementation with real business logic
            
        Raises:
            ComponentGenerationError: If generation fails
        """
        
        # Build detailed prompt based on component type
        system_prompt = self._get_system_prompt(component_type)
        user_prompt = self._build_component_prompt(
            component_type, component_name, component_description, 
            component_config, class_name
        )
        
        try:
            # Use robust LLM call with retry and circuit breaker - validation now inside retry loop
            generated_code = await self._call_llm_with_retries_and_validation(
                system_prompt, user_prompt, component_type, class_name, component_name
            )
            
            # Save generated code to a debug file for inspection
            import tempfile
            import os
            debug_file = os.path.join(tempfile.gettempdir(), f"debug_{component_name}.py")
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write(generated_code)
            print(f"Debug: Saved generated code to {debug_file}")
            
            # Also save to a fixed location for debugging
            with open('/tmp/last_generated_code.py', 'w', encoding='utf-8') as f:
                f.write(generated_code)
            
            return generated_code
            
        except Exception as e:
            raise ComponentGenerationError(
                f"Failed to generate component {component_name} via LLM: {e}\n"
                f"Component type: {component_type}\n"
                f"NO FALLBACKS - LLM generation is mandatory for ALL components."
            )
    
    async def _call_llm_with_retries_and_validation(
        self, 
        system_prompt: str, 
        user_prompt: str, 
        component_type: str, 
        class_name: str, 
        component_name: str
    ) -> str:
        """Call LLM with robust error handling, retries, circuit breaker AND validation feedback loop."""
        
        # Check circuit breaker
        if self.circuit_breaker_failures >= self.circuit_breaker_threshold:
            self.logger.error("circuit_breaker_open", {
                "failures": self.circuit_breaker_failures,
                "threshold": self.circuit_breaker_threshold,
                "timeout": self.circuit_breaker_timeout
            })
            raise ComponentGenerationError(
                f"Circuit breaker open: LLM service unavailable "
                f"({self.circuit_breaker_failures} consecutive failures). "
                f"Try again in {self.circuit_breaker_timeout} seconds."
            )
        
        last_exception = None
        validation_feedback = ""
        validation_errors = []
        
        # Log generation start
        generation_id = f"{component_name}_{int(time.time())}"
        self.logger.info("llm_generation_start", {
            "generation_id": generation_id,
            "component_type": component_type,
            "component_name": component_name,
            "class_name": class_name,
            "provider": "multi-provider",
            "model": "dynamic"
        })
        
        for attempt in range(self.retry_strategy.max_retries + 1):
            try:
                print(f"LLM call attempt {attempt + 1}/{self.retry_strategy.max_retries + 1}")
                
                # Adapt prompt with validation feedback from previous attempts
                adapted_user_prompt = self._build_adaptive_prompt(user_prompt, validation_feedback, attempt)
                
                # Log attempt
                attempt_start = time.time()
                self.logger.info("llm_generation_attempt", {
                    "generation_id": generation_id,
                    "attempt": attempt + 1,
                    "max_attempts": self.retry_strategy.max_retries + 1,
                    "has_validation_feedback": bool(validation_feedback),
                    "prompt_length": len(system_prompt) + len(user_prompt),
                    "system_prompt_length": len(system_prompt),
                    "user_prompt_length": len(adapted_user_prompt)
                })
                
                # Log sanitized prompt for audit trail (remove sensitive information)
                sanitized_prompt = self._sanitize_prompt_for_logging(adapted_user_prompt)
                self.logger.debug("llm_prompt_sent", {
                    "generation_id": generation_id,
                    "attempt": attempt + 1,
                    "prompt_preview": sanitized_prompt[:500] + "..." if len(sanitized_prompt) > 500 else sanitized_prompt,
                    "full_prompt_length": len(adapted_user_prompt)
                })
                
                # Create LLM request using standardized format
                request = LLMRequest(
                    system_prompt=system_prompt,
                    user_prompt=adapted_user_prompt,
                    max_tokens=4000,
                    temperature=0.3
                )
                
                # Make the multi-provider API call with automatic failover
                response = await self.multi_provider.generate(request)
                generated_code = response.content
                
                # Record attempt metric with provider from response
                self.metrics.increment("llm_generation_attempts", {
                    "component_type": component_type,
                    "provider": response.provider,
                    "model": response.model,
                    "attempt_number": str(attempt + 1)
                })
                
                # Log response received with provider info from response
                self.logger.info("llm_response_received", {
                    "generation_id": generation_id,
                    "attempt": attempt + 1,
                    "response_time": response.response_time,
                    "response_length": len(generated_code),
                    "provider": response.provider,
                    "model": response.model,
                    "tokens_used": response.tokens_used,
                    "cost_usd": response.cost_usd
                })
                
                # Log truncated response for audit trail
                response_preview = generated_code[:1000] + "..." if len(generated_code) > 1000 else generated_code
                self.logger.debug("llm_response_content", {
                    "generation_id": generation_id,
                    "attempt": attempt + 1,
                    "response_preview": response_preview,
                    "response_starts_with": generated_code[:100] if generated_code else "",
                    "response_ends_with": generated_code[-100:] if len(generated_code) > 100 else "",
                    "contains_code_blocks": "```" in generated_code,
                    "line_count": len(generated_code.split('\n')) if generated_code else 0
                })
                
                # Record response metrics using provider info from response
                self.metrics.histogram("llm_response_time", response.response_time, {
                    "component_type": component_type,
                    "provider": response.provider,
                    "model": response.model
                })
                
                self.metrics.histogram("llm_response_size", len(generated_code), {
                    "component_type": component_type,
                    "provider": response.provider,
                    "model": response.model
                })
                
                # Record cost metrics
                self.metrics.histogram("llm_cost_per_request", response.cost_usd, {
                    "component_type": component_type,
                    "provider": response.provider,
                    "model": response.model
                })
                
                self.metrics.histogram("llm_tokens_per_request", response.tokens_used, {
                    "component_type": component_type,
                    "provider": response.provider,
                    "model": response.model
                })
                
                # Post-process the generated code
                generated_code = self._post_process_generated_code(generated_code, component_name)
                
                # Debug: Save code after post-processing but before validation
                with open('/tmp/debug_code_after_postprocess.py', 'w') as f:
                    f.write(generated_code)
                print(f"Debug: Saved post-processed code to /tmp/debug_code_after_postprocess.py (length: {len(generated_code)})")
                
                # CRITICAL FIX: Validate generated code INSIDE retry loop
                try:
                    validation_start = time.time()
                    self._validate_generated_code(generated_code, component_type, class_name)
                    validation_time = time.time() - validation_start
                    
                    # Log successful validation with provider info
                    self.logger.info("llm_validation_success", {
                        "generation_id": generation_id,
                        "attempt": attempt + 1,
                        "validation_time": validation_time,
                        "code_length": len(generated_code),
                        "validation_type": "ast_compilation",
                        "post_processed": True,
                        "provider": response.provider,
                        "model": response.model,
                        "tokens_used": response.tokens_used,
                        "cost_usd": response.cost_usd
                    })
                    
                    # Log validation details for audit trail
                    self.logger.debug("llm_validation_details", {
                        "generation_id": generation_id,
                        "attempt": attempt + 1,
                        "validation_passed": True,
                        "validation_errors": [],
                        "code_preview": generated_code[:300] + "..." if len(generated_code) > 300 else generated_code,
                        "syntax_check": "passed",
                        "pattern_check": "passed"
                    })
                    
                    # Record validation success metric with provider info
                    self.metrics.increment("llm_validation_success", {
                        "component_type": component_type,
                        "provider": response.provider,
                        "model": response.model
                    })
                    
                    # Reset circuit breaker on success
                    self.circuit_breaker_failures = 0
                    print(f"✅ LLM generation successful with {response.provider} after {attempt + 1} attempt(s)")
                    print(f"   Tokens: {response.tokens_used}, Cost: ${response.cost_usd:.4f}, Time: {response.response_time:.2f}s")
                    
                    # Log final success
                    total_time = time.time() - attempt_start
                    self.logger.info("llm_generation_complete", {
                        "generation_id": generation_id,
                        "total_attempts": attempt + 1,
                        "total_time": total_time,
                        "component_type": component_type,
                        "component_name": component_name,
                        "success": True
                    })
                    
                    # Record generation success metrics with provider info
                    self.metrics.increment("llm_generation_success", {
                        "component_type": component_type,
                        "provider": response.provider,
                        "model": response.model,
                        "attempts_required": str(attempt + 1)
                    })
                    
                    # Record success rate by provider
                    self.metrics.increment("llm_provider_success_total", {
                        "provider": response.provider,
                        "model": response.model,
                        "component_type": component_type
                    })
                    
                    # Record first-attempt success rate
                    if attempt == 0:
                        self.metrics.increment("llm_first_attempt_success", {
                            "provider": response.provider,
                            "model": response.model,
                            "component_type": component_type
                        })
                    
                    # Record total generation time with provider info
                    generation_start_time = float(generation_id.split('_')[-1])
                    total_generation_time = time.time() - generation_start_time
                    self.metrics.histogram("llm_generation_total_time", total_generation_time, {
                        "component_type": component_type,
                        "provider": response.provider,
                        "model": response.model
                    })
                    
                    # Track circuit breaker recovery if there were previous failures
                    if self.circuit_breaker_failures > 0:
                        self.metrics.increment("llm_circuit_breaker_recovery", {
                            "provider": response.provider,
                            "model": response.model,
                            "failures_before_recovery": str(self.circuit_breaker_failures)
                        })
                        # Reset circuit breaker counter on success
                        self.circuit_breaker_failures = 0
                    
                    return generated_code
                    
                except ComponentGenerationError as validation_error:
                    # Classify the error type for proper retry handling
                    error_type = self._classify_error(validation_error)
                    validation_feedback = self._format_validation_feedback(validation_error)
                    print(f"❌ {error_type.value} on attempt {attempt + 1}: {validation_error}")
                    
                    # Get provider info from response if available
                    provider_name = getattr(response, 'provider', 'unknown') if 'response' in locals() else 'unknown'
                    model_name = getattr(response, 'model', 'unknown') if 'response' in locals() else 'unknown'
                    
                    # Log validation failure with detailed audit trail
                    self.logger.warning("llm_validation_failed", {
                        "generation_id": generation_id,
                        "attempt": attempt + 1,
                        "error_type": error_type.value,
                        "error_message": str(validation_error),
                        "validation_feedback": validation_feedback,
                        "component_type": component_type,
                        "component_name": component_name,
                        "provider": provider_name,
                        "model": model_name
                    })
                    
                    # Log detailed validation failure for debugging
                    self.logger.debug("llm_validation_failure_details", {
                        "generation_id": generation_id,
                        "attempt": attempt + 1,
                        "validation_passed": False,
                        "validation_errors": [str(validation_error)],
                        "code_preview": generated_code[:300] + "..." if len(generated_code) > 300 else generated_code,
                        "code_length": len(generated_code),
                        "syntax_issues": "syntax" in str(validation_error).lower(),
                        "pattern_issues": "pattern" in str(validation_error).lower(),
                        "placeholder_issues": "placeholder" in str(validation_error).lower(),
                        "will_retry": self.retry_strategy.should_retry(error_type, attempt)
                    })
                    
                    # Record validation failure metric (provider info already extracted above)
                    
                    self.metrics.increment("llm_validation_failures", {
                        "component_type": component_type,
                        "provider": provider_name,
                        "model": model_name,
                        "error_type": error_type.value
                    })
                    
                    # Record error type frequency by provider
                    self.metrics.increment("llm_error_type_frequency", {
                        "provider": provider_name,
                        "model": model_name,
                        "error_type": error_type.value,
                        "component_type": component_type
                    })
                    
                    # Track retry patterns
                    self.metrics.increment("llm_retry_patterns", {
                        "provider": provider_name,
                        "model": model_name,
                        "error_type": error_type.value,
                        "attempt_number": str(attempt + 1),
                        "will_retry": str(self.retry_strategy.should_retry(error_type, attempt))
                    })
                    
                    # Check if we should retry based on error type and attempt count
                    if not self.retry_strategy.should_retry(error_type, attempt):
                        self.logger.error("llm_generation_failed", {
                            "generation_id": generation_id,
                            "total_attempts": attempt + 1,
                            "final_error_type": error_type.value,
                            "final_error": str(validation_error),
                            "component_type": component_type,
                            "component_name": component_name
                        })
                        raise ComponentGenerationError(
                            f"LLM generation failed validation after {attempt + 1} attempts. "
                            f"Final validation error: {validation_error}"
                        )
                    
                    # Wait before next attempt (shorter for validation errors)
                    if attempt < self.retry_strategy.max_retries:
                        delay = self.retry_strategy.get_delay(attempt, error_type)
                        print(f"Retrying in {delay:.2f} seconds...")
                        time.sleep(delay)
                    
                    # Continue to next attempt with validation feedback
                    continue
                
            except ComponentGenerationError as validation_error:
                # Re-raise validation errors from the inner try block
                error_type = self._classify_error(validation_error)
                if not self.retry_strategy.should_retry(error_type, attempt):
                    raise
                else:
                    last_exception = validation_error
                    continue
                    
            except Exception as e:
                # API or network errors
                error_type = ErrorType.API_ERROR
                last_exception = e
                
                # Log API error (provider info not available during error)
                error_details = {
                    "generation_id": generation_id,
                    "attempt": attempt + 1,
                    "error_type": error_type.value,
                    "error_class": type(e).__name__,
                    "error_message": str(e),
                    "provider": "multi_provider",
                    "model": "dynamic"
                }
                
                # Provide more specific error information for timeouts
                if "timed out" in str(e).lower() or "timeout" in str(e).lower():
                    print(f"⏱️ LLM API timeout on attempt {attempt + 1}: {e}")
                    print(f"   Consider checking your network connection or LLM service status")
                    error_details["timeout"] = True
                    self.logger.warning("llm_api_timeout", error_details)
                    self.metrics.increment("llm_api_timeouts", {
                        "provider": "multi_provider",
                        "model": "dynamic"
                    })
                else:
                    print(f"LLM API call attempt {attempt + 1} failed: {e}")
                    self.logger.warning("llm_api_error", error_details)
                    self.metrics.increment("llm_api_errors", {
                        "provider": "multi_provider",
                        "model": "dynamic",
                        "error_class": type(e).__name__
                    })
                
                # Increment circuit breaker counter
                self.circuit_breaker_failures += 1
                
                # Check if we should retry based on error type and attempt count
                if not self.retry_strategy.should_retry(error_type, attempt):
                    self.logger.error("llm_api_failed", {
                        **error_details,
                        "circuit_breaker_failures": self.circuit_breaker_failures,
                        "giving_up": True
                    })
                    break
                
                # Wait before retrying
                if attempt < self.retry_strategy.max_retries:
                    delay = self.retry_strategy.get_delay(attempt, error_type)
                    print(f"Retrying in {delay:.2f} seconds...")
                    time.sleep(delay)
                else:
                    # All retries exhausted
                    break
        
        # All retries failed
        self.logger.error("llm_generation_exhausted", {
            "generation_id": generation_id,
            "total_attempts": self.retry_strategy.max_retries + 1,
            "last_error": str(last_exception),
            "circuit_breaker_failures": self.circuit_breaker_failures,
            "component_type": component_type,
            "component_name": component_name,
            "provider": "multi_provider",
            "model": "dynamic"
        })
        
        # Record generation failure metric
        self.metrics.increment("llm_generation_failures", {
            "component_type": component_type,
            "provider": "multi_provider",
            "model": "dynamic",
            "failure_reason": "exhausted_retries"
        })
        
        # Record provider failure tracking
        self.metrics.increment("llm_provider_failures_total", {
            "provider": "multi_provider",
            "model": "dynamic",
            "component_type": component_type,
            "total_attempts": str(self.retry_strategy.max_retries + 1)
        })
        
        # Record circuit breaker impact
        self.metrics.increment("llm_circuit_breaker_impact", {
            "provider": "multi_provider",
            "model": "dynamic",
            "failures_before_break": str(self.circuit_breaker_failures)
        })
        
        raise ComponentGenerationError(
            f"LLM service unavailable after {self.retry_strategy.max_retries + 1} attempts. "
            f"Last error: {last_exception}. "
            f"This indicates a systemic issue with the LLM service. "
            f"NO FALLBACKS AVAILABLE - LLM generation is mandatory."
        )
    
    def _post_process_generated_code(self, generated_code: str, component_name: str) -> str:
        """Post-process generated code to clean up formatting issues and fix common syntax errors."""
        import re
        
        # Handle case where LLM doesn't follow instructions
        print(f"Debug: Raw generated code starts with: {repr(generated_code[:50])}")
        
        # Check if response contains markdown code blocks
        if "```python" in generated_code or "```" in generated_code:
            print("Debug: Detected code block markers in response")
            # Extract code from markdown
            lines = generated_code.split('\n')
            code_lines = []
            in_code = False
            for line in lines:
                if line.strip() == "```python" or (line.strip() == "```" and not in_code):
                    in_code = True
                elif line.strip() == "```" and in_code:
                    in_code = False
                elif in_code:
                    code_lines.append(line)
            if code_lines:
                generated_code = '\n'.join(code_lines)
                print(f"Debug: Extracted {len(code_lines)} lines from code block")
        
        # Check if response starts with explanatory text
        first_line = generated_code.strip().split('\n')[0] if generated_code.strip() else ""
        if first_line and not (first_line.startswith(('import ', 'from ', '#', '"""')) or first_line.strip() == ""):
            print(f"Debug: Detected explanatory text at start: {repr(first_line[:50])}")
            # Try to find where the actual code starts
            lines = generated_code.split('\n')
            for i, line in enumerate(lines):
                if line.strip().startswith(('import ', 'from ', '#', '"""', 'class ')):
                    generated_code = '\n'.join(lines[i:])
                    print(f"Debug: Found code starting at line {i+1}")
                    break
        
        # Fix common syntax errors
        print("Debug: Checking for common syntax errors...")
        
        # Fix unbalanced parentheses/brackets in regex patterns
        # Look for patterns like 'class.*Source)' which should be 'class.*Source\)'
        patterns_to_fix = [
            (r'(class\.\*)(Source|Sink|Controller|Transformer|Store)\)', r'\1\2\\)'),
            (r'(isinstance\([^,]+,\s*)(Source|Sink|Controller|Transformer|Store)\)', r'\1\2\\)'),
            # Fix other common regex patterns with unescaped parentheses
            (r'(re\.compile\(["\'])([^"\']*[^\\])\)([^"\']*["\'])', r'\1\2\\)\3'),
            (r'(re\.match\(["\'])([^"\']*[^\\])\)([^"\']*["\'])', r'\1\2\\)\3'),
            (r'(re\.search\(["\'])([^"\']*[^\\])\)([^"\']*["\'])', r'\1\2\\)\3'),
        ]
        
        for pattern, replacement in patterns_to_fix:
            old_code = generated_code
            generated_code = re.sub(pattern, replacement, generated_code)
            if old_code != generated_code:
                print(f"Debug: Fixed regex pattern: {pattern}")
        
        # Check for and fix unbalanced parentheses
        def count_parens(text):
            open_count = text.count('(') - text.count(r'\(')
            close_count = text.count(')') - text.count(r'\)')
            return open_count, close_count
        
        open_parens, close_parens = count_parens(generated_code)
        if open_parens != close_parens:
            print(f"Warning: Unbalanced parentheses detected: {open_parens} open, {close_parens} close")
            # Try to fix by analyzing context
            lines = generated_code.split('\n')
            for i, line in enumerate(lines):
                line_open, line_close = count_parens(line)
                if line_open > line_close:
                    # Check if it's a string literal context
                    if ('re.compile(' in line or 're.match(' in line or 're.search(' in line) and '"' in line:
                        # Likely a regex pattern - add backslash before closing paren
                        fixed_line = re.sub(r'([^\\])\)(["\'])', r'\1\\)\2', line)
                        if fixed_line != line:
                            lines[i] = fixed_line
                            print(f"Debug: Fixed unescaped parenthesis in line {i+1}")
            generated_code = '\n'.join(lines)
        
        # Debug: Log first few lines of generated code
        print(f"\n--- Generated code preview for {component_name} ---")
        print(f"Total length: {len(generated_code)} chars")
        lines = generated_code.split('\n')[:15]  # Show more lines
        for i, line in enumerate(lines):
            # Show repr for empty or whitespace-only lines
            if not line.strip():
                print(f"{i+1}: <empty line>")
            else:
                print(f"{i+1}: {line}")
        lines_count = len(generated_code.split('\n'))
        if lines_count > 15:
            print(f"... ({lines_count - 15} more lines)")
        print("--- End preview ---\n")
        
        return generated_code

    def _build_adaptive_prompt(self, base_prompt: str, validation_feedback: str, attempt: int) -> str:
        """Build adaptive prompt that includes validation feedback from previous attempts with o3 optimization."""
        
        if attempt == 0 or not validation_feedback:
            return base_prompt
        
        # Use o3-specific reasoning for retry attempts
        reasoning_retry = self._get_o3_reasoning_prefix()
            
        # Analyze validation feedback to provide more specific guidance
        specific_fixes = []
        if "syntax" in validation_feedback.lower() or "syntaxerror" in validation_feedback.lower():
            specific_fixes.append("- SYNTAX ERROR DETECTED: Check all parentheses, brackets, and quotes are balanced")
            specific_fixes.append("- Ensure all regex patterns have escaped parentheses: use \\) not )")
            specific_fixes.append("- Verify proper indentation (4 spaces per level)")
            specific_fixes.append("- Example: Change re.compile(r'pattern)') to re.compile(r'pattern\\)')")
        if "unbalanced parenthesis" in validation_feedback.lower():
            specific_fixes.append("- UNBALANCED PARENTHESIS: Count all ( and ) to ensure they match")
            specific_fixes.append("- Check regex patterns - they often have unescaped parentheses")
            specific_fixes.append("- Look for missing closing parentheses in function calls")
            specific_fixes.append("- Example: if re.search(r'pattern)', text) should be if re.search(r'pattern\\)', text)")
        if "notimplementederror" in validation_feedback.lower():
            specific_fixes.append("- FORBIDDEN PATTERN: Remove ALL raise NotImplementedError statements")
            specific_fixes.append("- Replace with real implementation logic")
            specific_fixes.append("- Example: Instead of 'raise NotImplementedError', return actual data like {'result': 'processed'}")
        if "placeholder" in validation_feedback.lower() or "dummy" in validation_feedback.lower():
            specific_fixes.append("- PLACEHOLDER DETECTED: Remove all dummy/test values")
            specific_fixes.append("- Implement real business logic with meaningful data")
            specific_fixes.append("- Example: Instead of {'test': True}, return {'users': [actual_user_data]}")
        
        fixes_text = "\n".join(specific_fixes) if specific_fixes else ""
        
        # Add specific validation feedback to prompt
        adaptive_section = f"""

{reasoning_retry}CRITICAL: Previous attempt failed validation. You MUST fix these specific issues:

{validation_feedback}

SPECIFIC FIXES REQUIRED:
{fixes_text}

VALIDATION REQUIREMENTS:
- NO placeholder code (e.g., return {{"value": 42}}, pass, NotImplementedError)
- NO empty methods or classes  
- ALL methods must have real business logic implementation
- NO TODO comments or placeholder text in code
- CODE must be syntactically correct and complete

Please generate a corrected implementation that addresses ALL validation errors above.

Examples of correct business logic:
- For Sources: Generate real data like {{"id": str(uuid.uuid4()), "timestamp": time.time(), "data": {{...}}}}
- For Transformers: Apply actual transformations like data filtering, calculations, format conversion
- For Models: Implement real inference logic with confidence scores
- For Stores: Persist data to storage with proper error handling
- For APIEndpoints: Return real data structures like {{"users": [users_list], "status": "success"}}

CRITICAL SYNTAX REQUIREMENTS:
- ALWAYS use proper parentheses matching: ( ) must be balanced
- NEVER use placeholder returns like return {{"value": 42}}
- ALWAYS implement real business logic in methods
- ENSURE all function definitions end with proper indentation
- CHECK that all imports are valid and used correctly

FINAL VALIDATION BEFORE RESPONDING:
1. Count all opening parentheses ( - must equal closing parentheses )
2. Count all opening brackets [ - must equal closing brackets ]
3. Count all opening braces {{ - must equal closing braces }}
4. Verify all strings have matching quotes
5. Check all regex patterns have escaped closing parentheses \\)
6. Ensure 4-space indentation is consistent throughout
7. Confirm all imports are at the top and used in the code
"""
        
        return base_prompt + adaptive_section

    def _format_validation_feedback(self, validation_result) -> str:
        """Format validation errors into clear, actionable feedback for LLM retry."""
        
        feedback_parts = []
        
        # Handle string error messages (most common case)
        if isinstance(validation_result, str):
            return validation_result
        
        # Handle exception objects
        if isinstance(validation_result, Exception):
            return str(validation_result)
        
        # Handle structured validation result objects
        if hasattr(validation_result, 'placeholder_errors'):
            for error in validation_result.placeholder_errors:
                feedback_parts.append(f"- PLACEHOLDER DETECTED: {error.description} at line {error.line}")
        
        # Syntax errors
        if hasattr(validation_result, 'syntax_errors'):
            for error in validation_result.syntax_errors:
                feedback_parts.append(f"- SYNTAX ERROR: {error.message} at line {error.line}")
        
        # AST validation errors
        if hasattr(validation_result, 'ast_errors'):
            for error in validation_result.ast_errors:
                feedback_parts.append(f"- CODE STRUCTURE ERROR: {error.description}")
        
        # Method implementation errors
        if hasattr(validation_result, 'method_errors'):
            for error in validation_result.method_errors:
                feedback_parts.append(f"- MISSING IMPLEMENTATION: {error.method_name} - {error.description}")
        
        return "\n".join(feedback_parts) if feedback_parts else "Unknown validation error"

    def _classify_error(self, error: Exception) -> ErrorType:
        """Classify error to determine appropriate retry strategy"""
        error_msg = str(error).lower()
        error_type_name = type(error).__name__.lower()
        
        # Check for syntax errors - highest priority for quick fixes
        if ("syntax" in error_msg or "syntaxerror" in error_msg or "invalid syntax" in error_msg or
            "unbalanced parenthesis" in error_msg or "unmatched" in error_msg or
            "unexpected eof" in error_msg or "indentation" in error_msg or
            "position" in error_msg and "error" in error_msg or
            "compilation failed" in error_msg or "compile" in error_msg):
            return ErrorType.SYNTAX_ERROR
        
        # Check for pattern validation errors - need structural changes
        if ("missing required" in error_msg or 
            "composedcomponent" in error_msg or 
            "deprecated pattern" in error_msg or
            "process_item" in error_msg or
            "must inherit" in error_msg or
            "class name" in error_msg):
            return ErrorType.PATTERN_ERROR
        
        # Check for placeholder validation errors - need logic implementation
        if ("placeholder" in error_msg or 
            "notimplementederror" in error_msg or 
            "todo" in error_msg or
            "forbidden pattern" in error_msg or
            "dummy" in error_msg or
            "mock" in error_msg or
            "test data" in error_msg):
            return ErrorType.VALIDATION_ERROR
        
        # Check for API-specific errors
        if ("timeout" in error_msg or "timed out" in error_msg or
            "connection" in error_msg or "network" in error_msg or
            "api" in error_type_name or "http" in error_msg or
            "rate limit" in error_msg or "quota" in error_msg or
            "internal server error" in error_msg or "500" in error_msg or
            "502" in error_msg or "503" in error_msg or "504" in error_msg or
            "network error" in error_msg or "connection error" in error_msg or
            "connection refused" in error_msg or "connection timeout" in error_msg or
            "ssl error" in error_msg or "tls error" in error_msg):
            return ErrorType.API_ERROR
        
        # Default to validation error for ComponentGenerationError
        if isinstance(error, ComponentGenerationError):
            return ErrorType.VALIDATION_ERROR
        
        # Default to API error for other exceptions
        return ErrorType.API_ERROR

    # REMOVED: Dead code _call_llm_with_retries method (76 lines) - replaced by multi-provider system
    
    def _enhance_component_prompt(self, component_type: str, component_name: str) -> str:
        """Enhanced prompt to prevent placeholder generation."""
        return f"""
        CRITICAL: Generate complete, functional code with NO placeholders.
        
        FORBIDDEN PATTERNS:
        - TODO comments
        - placeholder values like "your_database_url"
        - NotImplementedError exceptions
        - pass statements in functional methods
        - Generic return statements like "return {{}}"
        
        REQUIRED IMPLEMENTATION:
        - All methods must have functional implementations
        - Use realistic default values, not placeholders
        - Include proper error handling
        - Implement actual business logic
        
        Component Type: {component_type}
        Component Name: {component_name}
        
        Generate production-ready code that passes validation.
        """

    def _get_system_prompt(self, component_type: str) -> str:
        """Get system prompt for component generation with standalone embedded base class"""
        # Optimize prompt for O3 reasoning model if being used
        # Check if we should use O3-style reasoning (will be determined by the multi-provider system)
        reasoning_prefix = self._get_o3_reasoning_prefix()
            
        # Create the complete standalone base class to embed
        STANDALONE_BASE_CLASS = '''
import logging
import time
import json
from typing import Dict, Any, Optional
from abc import ABC, abstractmethod
from dataclasses import dataclass, field


def get_logger(name: str) -> logging.Logger:
    """Create a standalone logger with proper formatting"""
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger


class StandaloneMetricsCollector:
    """Standalone metrics collector for observability"""
    
    def __init__(self, component_name: str):
        self.component_name = component_name
        self.metrics = {}
        self.logger = get_logger(f"metrics.{component_name}")
    
    def counter(self, name: str, value: int = 1, tags: Dict[str, str] = None):
        """Record a counter metric"""
        key = f"{self.component_name}.{name}"
        self.metrics[key] = self.metrics.get(key, 0) + value
        self.logger.debug(f"Counter {key}: {self.metrics[key]}")
    
    def gauge(self, name: str, value: float, tags: Dict[str, str] = None):
        """Record a gauge metric"""
        key = f"{self.component_name}.{name}"
        self.metrics[key] = value
        self.logger.debug(f"Gauge {key}: {value}")
    
    def histogram(self, name: str, value: float, tags: Dict[str, str] = None):
        """Record a histogram metric"""
        key = f"{self.component_name}.{name}"
        if key not in self.metrics:
            self.metrics[key] = []
        self.metrics[key].append(value)
        self.logger.debug(f"Histogram {key}: {value}")
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get all recorded metrics"""
        return self.metrics.copy()


class StandaloneTracer:
    """Standalone tracer for observability"""
    
    def __init__(self, component_name: str):
        self.component_name = component_name
        self.logger = get_logger(f"tracer.{component_name}")
    
    def start_span(self, name: str, tags: Dict[str, str] = None):
        """Start a new span"""
        return StandaloneSpan(name, self.logger, tags)


class StandaloneSpan:
    """Standalone span implementation"""
    
    def __init__(self, name: str, logger: logging.Logger, tags: Dict[str, str] = None):
        self.name = name
        self.logger = logger
        self.tags = tags or {}
        self.start_time = time.time()
    
    def __enter__(self):
        self.logger.debug(f"Starting span: {self.name}")
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        duration = time.time() - self.start_time
        self.logger.debug(f"Completed span: {self.name} ({duration:.3f}s)")
    
    def set_attribute(self, key: str, value: Any):
        """Set span attribute"""
        self.tags[key] = str(value)
    
    def set_tag(self, key: str, value: str):
        """Set span tag"""
        self.tags[key] = value


@dataclass
class ComponentStatus:
    """Status information for a component"""
    is_running: bool = False
    is_healthy: bool = True
    items_processed: int = 0
    errors_encountered: int = 0
    last_error: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class ComposedComponent:
    """
    Standalone base class for all components.
    Provides all functionality without requiring autocoder_cc imports.
    """
    
    def __init__(self, name: str, config: Dict[str, Any] = None):
        self.name = name
        self.config = config or {}
        self.logger = get_logger(f"Component.{name}")
        self.metrics_collector = StandaloneMetricsCollector(name)
        self.tracer = StandaloneTracer(name)
        self.created_at = time.time()
        
        # Component state
        self._status = ComponentStatus()
        
        self.logger.info(f"Component {self.name} initialized")
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get component health status"""
        return {
            'status': 'healthy' if self._status.errors_encountered == 0 else 'degraded',
            'component': self.name,
            'type': self.__class__.__name__,
            'error_count': self._status.errors_encountered,
            'last_error': self._status.last_error,
            'uptime': time.time() - self.created_at,
            'items_processed': self._status.items_processed,
            'is_running': self._status.is_running,
            'is_healthy': self._status.is_healthy
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """Async health check"""
        return self.get_health_status()
    
    def handle_error(self, error: Exception, context: str = ""):
        """Handle and log errors"""
        self._status.errors_encountered += 1
        error_msg = f"{context}: {str(error)}" if context else str(error)
        self._status.last_error = error_msg
        self._status.is_healthy = False
        self.logger.error(f"Error in {self.name}: {error_msg}")
        self.metrics_collector.increment("errors")
    
    def increment_processed(self):
        """Increment processed items counter"""
        self._status.items_processed += 1
        self.metrics_collector.increment("items_processed")
    
    async def setup(self, harness_context: Optional[Dict[str, Any]] = None):
        """Initialize the component"""
        self._status.is_running = True
        self.logger.info(f"Component {self.name} setup completed")
    
    async def cleanup(self):
        """Cleanup resources"""
        self._status.is_running = False
        self.logger.info(f"Component {self.name} cleanup completed")
'''
            
        return f"""{reasoning_prefix}You are an expert Python developer generating standalone components that run independently without any framework dependencies.

CRITICAL STANDALONE REQUIREMENTS:
1. Generate COMPLETE, STANDALONE implementations with minimal external imports
2. EMBED the complete base class functionality directly in the generated file
3. ALLOW imports from autocoder_cc.blueprint_language.architectural_templates.* for architectural patterns
4. ALL core functionality must be self-contained in the generated file
5. Include complete observability functionality (logging, metrics, tracing)

MANDATORY STANDALONE BASE CLASS TO INCLUDE:
Every generated component MUST start with this complete base class code:

{STANDALONE_BASE_CLASS}

COMPONENT IMPLEMENTATION REQUIREMENTS:
- Inherit from ComposedComponent (defined above)
- Implement real business logic, no placeholders
- Use embedded observability functionality
- Handle errors gracefully with self.handle_error()
- Update metrics with self.metrics_collector
- Use tracing with self.tracer.start_span()
- Focus on business logic - architectural patterns will be added automatically

FORBIDDEN PATTERNS:
- from autocoder_cc.* imports - FORBIDDEN (all functionality must be self-contained)
- raise NotImplementedError statements - FORBIDDEN
- pass statements as function bodies - FORBIDDEN  
- TODO comments or FIXME comments - FORBIDDEN
- placeholder logic or dummy returns - FORBIDDEN
- return {{"value": 42}} type patterns - FORBIDDEN

3. NO pass statements as function bodies - FORBIDDEN  
4. NO TODO comments or FIXME comments - FORBIDDEN
5. NO placeholder logic or dummy returns - FORBIDDEN
6. MUST include real business logic that actually works
7. MUST handle errors gracefully with proper exception handling
8. MUST return meaningful data structures
9. Follow the standalone component pattern using embedded base class
10. Include proper error handling and logging

ASYNC INITIALIZATION REQUIREMENTS:
- NEVER call anyio.run() or asyncio.run() in __init__ methods
- Use async methods for database/network initialization
- Initialize connections in async lifecycle methods
- Use proper async/await patterns throughout

SYNTAX REQUIREMENTS - CRITICAL FOR PREVENTING ERRORS:
- ENSURE all parentheses, brackets, and braces are balanced
- ESCAPE closing parentheses in regex patterns with backslash: \\)
- USE proper Python 3.8+ syntax
- VALIDATE that all strings are properly closed
- CHECK that all indentation is consistent (4 spaces)
- AVOID syntax errors at all costs - code MUST compile
- NEVER use blocking async calls in __init__ methods

COMMON SYNTAX ERROR PREVENTION:
1. REGEX PATTERNS: Always escape closing parentheses in regex
   - WRONG: re.compile(r'class.*Source)')
   - CORRECT: re.compile(r'class.*Source\\)')
   - WRONG: re.search(r'pattern)', text)
   - CORRECT: re.search(r'pattern\\)', text)

2. PARENTHESES BALANCING: Count opening and closing parentheses
   - Every opening parenthesis ( must have a matching closing parenthesis )
   - Every opening bracket [ must have a matching closing bracket ]
   - Every opening brace {{ must have a matching closing brace }}

3. STRING QUOTATION: Ensure all strings are properly closed
   - WRONG: "unclosed string
   - CORRECT: "properly closed string"
   - WRONG: 'mixed "quotes'
   - CORRECT: "consistent quotes"

4. INDENTATION: Use exactly 4 spaces per level
   - WRONG: 2 spaces or tabs
   - CORRECT: 4 spaces for each indentation level

5. IMPORTS: Ensure all imports are valid and used
   - Import only what you need
   - Use full import paths
   - Avoid circular imports

SYNTAX VALIDATION CHECKLIST:
- [ ] All parentheses balanced
- [ ] All brackets balanced  
- [ ] All braces balanced
- [ ] All strings properly closed
- [ ] Consistent 4-space indentation
- [ ] Valid Python syntax
- [ ] All imports are correct

RESPONSE FORMAT:
- Respond with ONLY Python code
- Do NOT include any explanatory text or markdown formatting
- Do NOT wrap code in ```python``` blocks
- Start directly with imports and class definition
- The entire response should be valid Python that can be executed
- Double-check syntax before responding
- ENSURE all parentheses, brackets, and braces are properly balanced
- VALIDATE syntax before responding - the code MUST compile without errors

Component Type: {component_type}

STANDALONE COMPONENT ARCHITECTURE:
- ALL components use ComposedComponent (embedded in same file) - Self-contained functionality
- SINGLE unified method: async def process_item(self, item: Any) -> Any
- All capabilities embedded in the generated file (no external dependencies)
- Component behavior determined by embedded functionality and configuration

CORRECT IMPORTS:
- NO external autocoder_cc imports (all functionality embedded)
- Supporting imports: from typing import Dict, Any, Optional
- Standard library: import asyncio, logging, time, json
- For specific functionality: import appropriate libraries (httpx, json, etc.)

STANDALONE COMPONENT PATTERN:
```python
# Embedded base class code goes here (ComposedComponent, etc.)

class GeneratedComponent_{component_type}(ComposedComponent):
    def __init__(self, name: str, config: Dict[str, Any] = None):
        super().__init__(name, config)
        # Component-specific initialization here
        
    async def process_item(self, item: Any) -> Any:
        # Single method handles component-specific business logic
        # Use embedded observability: self.logger, self.metrics_collector, self.tracer
        # Return processed result for next component in pipeline
```


COMPONENT BEHAVIOR PATTERNS:
- Source components: process_item(None) -> generate and return data
- Transformer components: process_item(input_data) -> return transformed data
- Sink components: process_item(input_data) -> handle output, return metadata
- Model components: process_item(input_data) -> return inference results
- Store components: process_item(input_data) -> persist data, return confirmation

IMPORTANT: Generate production-ready standalone code with embedded functionality."""
    
    def _build_context_aware_prompt(
        self,
        component_type: str,
        component_name: str,
        component_description: str,
        component_config: Dict[str, Any],
        class_name: str,
        system_context: Optional[Dict[str, Any]] = None
    ) -> str:
        """Build enhanced context-aware prompt with system relationships and quality guidance."""
        
        # Build system context awareness
        system_awareness = ""
        if system_context:
            system_awareness = self._build_system_context_section(system_context, component_name, component_type)
        
        # Get base component prompt
        base_prompt = self._build_component_prompt(
            component_type, component_name, component_description, component_config, class_name
        )
        
        # Enhanced prompt with system awareness
        enhanced_prompt = f"""
{system_awareness}

ENHANCED GENERATION CONTEXT:
- Generate components with awareness of system-wide architecture
- Optimize for integration patterns and data flow requirements
- Follow quality patterns from successful system generations
- Consider performance implications of component interactions

{base_prompt}

CONTEXT-AWARE REQUIREMENTS:
- Design component to integrate seamlessly with system pipeline
- Follow data transformation patterns appropriate for position in pipeline
- Implement error handling that considers downstream component dependencies
- Use logging and metrics that align with system-wide observability strategy
"""
        return enhanced_prompt
    
    def _build_system_context_section(self, system_context: Dict[str, Any], current_component: str, component_type: str) -> str:
        """Build system context awareness section for enhanced prompting."""
        context_section = "\n=== SYSTEM CONTEXT AWARENESS ===\n"
        
        # Add component relationships
        if 'components' in system_context:
            components = system_context['components']
            context_section += f"\nSYSTEM COMPONENTS ({len(components)} total):\n"
            
            upstream_components = []
            downstream_components = []
            
            for comp in components:
                if comp['name'] != current_component:
                    comp_info = f"- {comp['name']} ({comp['type']}): {comp.get('description', 'No description')}"
                    context_section += comp_info + "\n"
                    
                    # Determine data flow relationships
                    if self._is_upstream_component(comp['type'], component_type):
                        upstream_components.append(comp)
                    elif self._is_downstream_component(comp['type'], component_type):
                        downstream_components.append(comp)
            
            # Add data flow context
            if upstream_components:
                context_section += f"\nUPSTREAM COMPONENTS (data sources for {current_component}):\n"
                for comp in upstream_components:
                    context_section += f"- {comp['name']} ({comp['type']}) -> expects data integration\n"
            
            if downstream_components:
                context_section += f"\nDOWNSTREAM COMPONENTS (data consumers from {current_component}):\n"
                for comp in downstream_components:
                    context_section += f"- {comp['name']} ({comp['type']}) -> will process your output\n"
        
        # Add system requirements
        if 'system_requirements' in system_context:
            req = system_context['system_requirements']
            context_section += f"\nSYSTEM REQUIREMENTS:\n"
            context_section += f"- Message Volume: {req.get('message_volume', 'Unknown')} messages/sec\n"
            context_section += f"- Max Latency: {req.get('max_latency', 'Unknown')} ms\n"
            context_section += f"- Durability Required: {req.get('durability_required', False)}\n"
            context_section += f"- Consistency Required: {req.get('consistency_required', False)}\n"
        
        # Add quality guidance
        context_section += f"\nQUALITY OPTIMIZATION GUIDANCE:\n"
        context_section += f"- Implement robust error handling for system-wide reliability\n"
        context_section += f"- Use structured logging with correlation IDs for distributed tracing\n"
        context_section += f"- Include metrics that support system-wide performance monitoring\n"
        context_section += f"- Design for horizontal scaling if system requirements indicate high throughput\n"
        
        context_section += "\n=== END SYSTEM CONTEXT ===\n"
        return context_section
    
    def _is_upstream_component(self, source_type: str, target_type: str) -> bool:
        """Determine if source component is upstream from target in typical data flow."""
        # Define typical data flow patterns
        flow_order = ['Source', 'Transformer', 'Store', 'APIEndpoint', 'Sink']
        
        try:
            source_idx = flow_order.index(source_type)
            target_idx = flow_order.index(target_type)
            return source_idx < target_idx
        except ValueError:
            return False
    
    def _is_downstream_component(self, source_type: str, target_type: str) -> bool:
        """Determine if source component is downstream from target in typical data flow."""
        return self._is_upstream_component(target_type, source_type)

    def _build_component_prompt(
        self, 
        component_type: str,
        component_name: str,
        component_description: str,
        component_config: Dict[str, Any],
        class_name: str
    ) -> str:
        """Build component-specific prompt with strict type enforcement."""
        
        if component_type == "Store":
            return f"""
            CRITICAL: You are generating a STANDALONE STORE component.
            
            MANDATORY REQUIREMENTS:
            - Class name MUST be: {class_name}
            - Component type MUST be: Store
            - Inherits from: ComposedComponent (embedded in same file)
            - Purpose: Data persistence and storage
            - MUST include the complete embedded base class code at the top
            
            FORBIDDEN:
            - ANY imports from autocoder_cc.* packages
            - ComposedComponent imports or usage
            - External framework dependencies
            
            REQUIRED IMPLEMENTATION:
            - process_item() method for data persistence
            - Database connection management using standalone code
            - Async database operations
            - Real database operations (not placeholders)
            
            Component Details:
            - Name: {component_name}
            - Class Name: {class_name}
            - Description: {component_description or f'A {component_type} component for data storage'}
            - Configuration: {json.dumps(component_config, indent=2) if component_config else 'Default configuration'}
            """
        elif component_type == "Sink":
            return f"""
            CRITICAL: You are generating a STANDALONE SINK component.
            
            MANDATORY REQUIREMENTS:
            - Class name MUST be: {class_name}
            - Component type MUST be: Sink
            - Inherits from: ComposedComponent (embedded in same file)
            - Purpose: Data consumption and processing
            - MUST include the complete embedded base class code at the top
            
            FORBIDDEN:
            - ANY imports from autocoder_cc.* packages
            - ComposedComponent imports or usage
            - External framework dependencies
            
            REQUIRED IMPLEMENTATION:
            - process_item() method for data consumption
            - Real data processing logic
            - Output handling (file, API, console, etc.)
            
            Component Details:
            - Name: {component_name}
            - Class Name: {class_name}
            - Description: {component_description or f'A {component_type} component for data consumption'}
            - Configuration: {json.dumps(component_config, indent=2) if component_config else 'Default configuration'}
            """
        
        # Base prompt structure for other component types
        prompt = f"""Generate a complete STANDALONE {component_type} component implementation.

Component Details:
- Name: {component_name}
- Class Name: {class_name}
- Description: {component_description or f'A {component_type} component for data processing'}
- Configuration: {json.dumps(component_config, indent=2) if component_config else 'Default configuration'}

CRITICAL STANDALONE REQUIREMENTS:
1. MUST include the complete embedded base class code at the top of the file
2. Inherit from ComposedComponent (embedded in same file)
3. Implement ALL required methods with REAL logic (no placeholders)
4. NO imports from autocoder_cc.* packages - FORBIDDEN
5. Include proper logging using embedded get_logger function
6. Handle errors gracefully using self.handle_error()
7. CRITICAL: Ensure perfect Python syntax - no unbalanced parentheses
8. CRITICAL: Escape regex patterns properly - use \\) not )
9. CRITICAL: All code must compile without syntax errors

SYNTAX EXAMPLES TO FOLLOW:
- CORRECT: re.compile(r"class.*Source\\)")  # Escaped parenthesis
- WRONG: re.compile(r"class.*Source)")     # Unescaped will cause error
- CORRECT: pattern = r"test\\(\\)"          # Both parentheses escaped
- WRONG: pattern = r"test()"                # Will cause regex error
"""
        
        # Add component-specific requirements using standalone pattern
        if component_type == "Source":
            prompt += f"""
Source-specific STANDALONE requirements:
- MUST include embedded base class code at top of file
- Inherit from ComposedComponent (embedded in same file) 
- Constructor signature: def __init__(self, name: str, config: Dict[str, Any] = None):
- Call parent constructor: super().__init__(name, config)
- Implement async def process_item(self, item: Any = None) -> Any method
- IGNORE input_data parameter for source components (sources generate data)
- Return ONE data item per call - the framework handles iteration
- Use component configuration to determine data generation behavior

CRITICAL DOCKER NETWORKING CONFIGURATION:
- NEVER use localhost or 127.0.0.1 for inter-service communication
- ALWAYS use Docker service names as hostnames (e.g., "app", "postgres", "kafka")
- Use internal port numbers (e.g., 8080, 5432, 9092) NOT mapped external ports
- Get connection details from config with Docker-compatible defaults
- Use component-specific service names and appropriate internal ports
- Extract host and port values using config.get with sensible defaults for the service type
- Database components should use database service names and database ports
- Kafka components should use kafka service names and kafka ports
- Web components should use web service names and web ports

HTTP/API SOURCE COMPONENTS MUST:
- Initialize host from config using appropriate service name for this component
- Initialize port from config using appropriate internal port for this service
- Use httpx client for HTTP requests: httpx.AsyncClient()
- Make requests using the configured host and port values
- NEVER use localhost URLs in Docker environment

NETWORKING INITIALIZATION REQUIREMENTS:
- Extract host and port from component configuration
- Use service-specific defaults appropriate for the component type
- Avoid hardcoded values like "app" or generic port numbers
- Use the actual component name or service type for meaningful hostnames
        
    async def process_item(self, item: Any = None) -> Any:
        # Use Docker networking for HTTP requests
        url = f"http://{{self.host}}:{{self.port}}/messages"
        async with httpx.AsyncClient() as client:
            response = await client.get(url)
            return response.json()

- Data should be based on the component description and configuration
- If it's an API source, implement real HTTP calls with httpx using Docker networking
- If it's a data generator, generate meaningful test data
- Use embedded observability: self.logger, self.metrics_collector, self.tracer
"""
        elif component_type == "Transformer":
            prompt += """
Transformer-specific STANDALONE requirements:
- MUST include embedded base class code at top of file
- Inherit from ComposedComponent (embedded in same file)
- Constructor signature: def __init__(self, name: str, config: Dict[str, Any] = None):
- Call parent constructor: super().__init__(name, config)
- Implement async def process_item(self, item: Any) -> Any method
- Transform item based on the component description and configuration
- Return the transformed data
- Preserve input data structure while adding transformations
- Handle edge cases and invalid inputs
- Use embedded observability: self.logger, self.metrics_collector, self.tracer
- Handle errors with self.handle_error()
- Update metrics with self.increment_processed()
"""
        # Note: Sink section is already handled above in the special case
        elif component_type == "Sink" and "Complete STANDALONE" not in prompt:
            prompt += """
Sink-specific STANDALONE requirements:
- MUST include embedded base class code at top of file
- Inherit from ComposedComponent (embedded in same file)
- Constructor signature: def __init__(self, name: str, config: Dict[str, Any] = None):
- Call parent constructor: super().__init__(name, config)
- Implement async def process_item(self, item: Any) -> Any method
- Handle output of item based on the component description
- Store or output data based on configuration (file, database, API, etc.)
- Return metadata about the output operation
- Handle output failures gracefully
- Use embedded observability: self.logger, self.metrics_collector, self.tracer
- Handle errors with self.handle_error()
- Update metrics with self.increment_processed()
"""
        elif component_type == "Model":
            prompt += """
Model-specific STANDALONE requirements:
- MUST include embedded base class code at top of file
- Inherit from ComposedComponent (embedded in same file)
- Constructor signature: def __init__(self, name: str, config: Dict[str, Any] = None):
- Call parent constructor: super().__init__(name, config)
- Implement async def process_item(self, item: Any) -> Any method
- Load model in __init__ or lazy-load in process_item method
- Process item through model to generate predictions
- Generate realistic inference results based on inputs
- Include confidence scores or probabilities in results
- Use embedded observability: self.logger, self.metrics_collector, self.tracer
- Handle errors with self.handle_error()
- Update metrics with self.increment_processed()
"""
        # Note: Store section is already handled above in the special case  
        elif component_type == "Store" and "Complete STANDALONE" not in prompt:
            prompt += """
Store-specific STANDALONE requirements:
- MUST include embedded base class code at top of file
- Inherit from ComposedComponent (embedded in same file)
- Constructor signature: def __init__(self, name: str, config: Dict[str, Any] = None):
- Call parent constructor: super().__init__(name, config)
- CRITICAL: NEVER call anyio.run() or asyncio.run() in __init__ method
- Initialize storage_type and connection variables in __init__
- Implement async def process_item(self, item: Any) -> Any method
- Handle data persistence in process_item method
- Use proper async initialization patterns
- Return confirmation/metadata about storage operation
- Use embedded observability: self.logger, self.metrics_collector, self.tracer
- Handle errors with self.handle_error()
- Update metrics with self.increment_processed()

CRITICAL DOCKER DATABASE NETWORKING CONFIGURATION:
- NEVER use localhost or 127.0.0.1 for database connections in Docker
- ALWAYS use Docker service names as database hostnames (e.g., "postgres", "mysql", "mongodb")
- Use internal port numbers (5432 for postgres, 3306 for mysql) NOT mapped external ports
- Get database connection details from config with Docker-compatible defaults:
  * config.get("db_host", "postgres") - use postgres service name, not localhost
  * config.get("db_port", 5432) - use internal postgres port (5432)
  * config.get("db_name", "app_db") - database name
  * config.get("db_user", "postgres") - database user
  * config.get("db_password", "secure_password") - database password
"""
        elif component_type == "APIEndpoint":
            prompt += """
APIEndpoint-specific STANDALONE requirements (FastAPI):
- MUST include embedded base class code at top of file
- Inherit from ComposedComponent (embedded in same file)
- Constructor signature: def __init__(self, name: str, config: Dict[str, Any] = None):
- Call parent constructor: super().__init__(name, config)
- CRITICAL: NEVER call anyio.run() or asyncio.run() in __init__ method
- Initialize port and host variables in __init__
- Implement async def process_item(self, item: Any) -> Any method for handling HTTP requests
- Implement proper error handling and validation
- The process_item method should handle HTTP request processing
- Use embedded observability: self.logger, self.metrics_collector, self.tracer
- Handle errors with self.handle_error()
- Update metrics with self.increment_processed()

CRITICAL DOCKER NETWORKING CONFIGURATION FOR API ENDPOINTS:
- Use internal Docker port (8080) as default, NOT external mapped ports
- Listen on 0.0.0.0 to accept connections from other Docker containers
- API endpoints should be accessible via Docker service name
- Database connections must use Docker service names (postgres, mysql, etc.)
- External service calls must use Docker service names when applicable

Example structure:
    def __init__(self, name: str, config: Dict[str, Any] = None):
        super().__init__(name, config)
        self.port = config.get("port", 8080)  # Internal Docker port
        self.host = config.get("host", "0.0.0.0")  # Listen on all interfaces
        self._initialized = False
    
    async def process_item(self, item: Any = None) -> Any:
        try:
            response = {
                "status": "success",
                "data": "API response data",
                "timestamp": time.time(),
                "service_host": self.host,
                "service_port": self.port
            }
            self.logger.info(f"API request processed: {response}")
            self.increment_processed()
            return response
        except Exception as e:
            self.handle_error(e, "API request processing")
            return {"status": "error", "message": str(e)}
"""
        
        prompt += """
CRITICAL: Generate ONLY Python code. Do NOT include any explanatory text before or after the code.
Do NOT wrap the code in markdown code blocks (```python).
Start directly with the Python imports and code.

Generate the complete Python file including:
- All necessary imports
- Complete class implementation  
- All required methods with real logic
- NO placeholders, TODOs, or return {"value": 42} patterns

The response should be valid Python code that can be saved directly to a .py file.
"""
        
        return prompt
    
    def _get_o3_reasoning_prefix(self) -> str:
        """Get O3-specific reasoning prefix - simplified for better results"""
        return """Generate a complete, working Python component. 

Think step by step:
1. Include the full embedded base class code first
2. Create the component class that inherits from ComposedComponent  
3. Implement ALL methods with real business logic (no placeholders)
4. Ensure perfect Python syntax

"""
    
    def _get_o3_optimized_prompt(self, component_type: str, context: Dict[str, Any]) -> str:
        """
        Simplified O3-specific prompt - direct and focused for better results
        """
        base_prompt = f"""
Generate a complete {component_type} component with these requirements:

FORBIDDEN: return {{"value": 42}}, TODO, FIXME, NotImplementedError, pass statements, localhost

REQUIRED STRUCTURE:
1. All imports at top
2. Complete embedded base class code (ComposedComponent, etc.)
3. Component class inheriting from ComposedComponent
4. Real business logic in process_item method
5. Perfect Python syntax

Component: {component_type}
Config: {context}

Output ONLY valid Python code starting with imports.
"""
        return base_prompt
    
    def _build_anti_placeholder_prompt(self, component_type: str, context: Dict[str, Any]) -> str:
        """Simplified anti-placeholder prompt for better o3 results"""
        return f"""
Previous generation had placeholder code. Fix this:

FORBIDDEN: return {{"value": 42}}, TODO, FIXME, NotImplementedError, pass, localhost

Generate a complete working {component_type} with:
- Full embedded base class code
- Component class with real business logic
- Complete process_item method implementation
- Proper error handling
- Valid Python syntax

Context: {context}

Start with imports, end with working component class.
"""

    def _build_maximum_context_prompt(self, component_type: str, context: Dict[str, Any]) -> str:
        """Simplified final attempt prompt for o3"""
        return f"""
FINAL ATTEMPT - Generate complete working Python code.

Type: {component_type}
Config: {json.dumps(context, indent=2)}

REQUIREMENTS:
1. Include full embedded base class code first
2. Create component class inheriting from ComposedComponent  
3. Implement process_item method with real business logic
4. Use Docker service names (not localhost)
5. Perfect Python syntax - no errors
6. NO placeholder patterns: return {{"value": 42}}, TODO, NotImplementedError

Generate complete Python file starting with imports.
"""
    
    def validate_python_syntax(self, code: str) -> tuple[bool, str]:
        """Replace subprocess-based validation with robust AST parsing."""
        try:
            import ast
            
            # Parse the code into an AST
            tree = ast.parse(code)
            
            # Compile to catch compilation errors
            compile(tree, '<generated_code>', 'exec')
            
            # Check for placeholder patterns using AST
            placeholder_issues = self._detect_placeholders_ast(tree)
            if placeholder_issues:
                return False, f"Placeholder patterns found: {placeholder_issues}"
            
            # Check for async issues using AST
            async_issues = self._detect_async_issues_ast(tree)
            if async_issues:
                return False, f"Async issues found: {async_issues}"
            
            return True, "Validation passed"
            
        except SyntaxError as e:
            return False, f"Syntax error at line {e.lineno}: {e.msg}"
        except Exception as e:
            return False, f"Compilation error: {e}"

    def _detect_placeholders_ast(self, tree) -> list[str]:
        """Use AST to detect placeholder patterns."""
        import ast
        issues = []
        
        for node in ast.walk(tree):
            # Check for TODO comments
            if isinstance(node, ast.Expr) and isinstance(node.value, ast.Constant):
                if isinstance(node.value.value, str) and "TODO" in node.value.value:
                    issues.append(f"TODO comment at line {node.lineno}")
            
            # Check for NotImplementedError
            if isinstance(node, ast.Raise) and isinstance(node.exc, ast.Call):
                if isinstance(node.exc.func, ast.Name) and node.exc.func.id == "NotImplementedError":
                    issues.append(f"NotImplementedError at line {node.lineno}")
            
            # Check for pass statements in methods
            if isinstance(node, ast.FunctionDef) and len(node.body) == 1:
                if isinstance(node.body[0], ast.Pass):
                    issues.append(f"Pass statement in method {node.name} at line {node.lineno}")
        
        return issues

    def _detect_async_issues_ast(self, tree) -> list[str]:
        """Use AST to detect async issues."""
        import ast
        issues = []
        
        for node in ast.walk(tree):
            # Check for blocking async calls in __init__ methods
            if isinstance(node, ast.FunctionDef) and node.name == "__init__":
                for child in ast.walk(node):
                    if isinstance(child, ast.Call):
                        if isinstance(child.func, ast.Attribute):
                            if (isinstance(child.func.value, ast.Name) and 
                                child.func.value.id in ['anyio', 'asyncio'] and
                                child.func.attr == 'run'):
                                issues.append(f"Blocking async call {child.func.value.id}.{child.func.attr}() in __init__")
        
        return issues

    def validate_no_placeholders(self, code: str) -> bool:
        """Enhanced validation using AST-based analysis."""
        # Use the new AST-based validation
        valid, message = self.validate_python_syntax(code)
        if not valid:
            raise ValueError(message)
        
        # Additional string-based checks for obvious placeholders
        forbidden_patterns = [
            'raise NotImplementedError',
            'TODO:',
            'FIXME:',
            'pass  # Implement',
            'return {}  # Placeholder',
            'return {"value": 42}',
            'return {"test": True}',
            'dummy_value',
            'placeholder'
        ]
        
        clean_code = code.strip()
        for pattern in forbidden_patterns:
            if pattern in clean_code:
                raise ValueError(f"Generated code contains forbidden pattern: {pattern}")
        
        return True
    
    def _validate_functional_implementation(self, code: str) -> bool:
        """
        Validate that generated code is truly functional, not placeholder
        CRITICAL: Address Gemini finding of placeholder pattern generation
        """
        import re
        
        # Check for forbidden patterns (Gemini confirmed these exist)
        forbidden_patterns = [
            r'return\s*\{\s*["\']value["\']\s*:\s*42\s*\}',  # {"value": 42} pattern
            r'return\s*\{\s*["\']test["\']\s*:\s*True\s*\}',  # {"test": True} pattern
            r'return\s*\{\s*\}.*placeholder',                # Empty dict with placeholder comment
            r'TODO:|FIXME:|pass\s*#',                        # TODO/FIXME/pass comments
            r'NotImplementedError',                          # NotImplementedError
            r'raise\s+NotImplementedError',                  # raise NotImplementedError
            r'pass\s*$',                                     # Pass statements as method body
            r'pass\s*\n\s*$',                               # Pass statements with newline
            r'localhost|127\.0\.0\.1',                      # Hardcoded localhost
            r'your_[a-z_]+_url',                            # Placeholder URLs
            r'dummy_\w+',                                    # Dummy variables
            r'mock_\w+',                                     # Mock variables
        ]
        
        for pattern in forbidden_patterns:
            matches = re.findall(pattern, code, re.IGNORECASE | re.MULTILINE)
            if matches:
                print(f"❌ Found forbidden pattern '{pattern}': {matches}")
                return False
        
        # Verify actual business logic implementation
        return self._verify_business_logic_implementation(code)
    
    def _verify_business_logic_implementation(self, code: str) -> bool:
        """Verify that the code contains actual business logic, not just structure"""
        import ast
        
        try:
            tree = ast.parse(code)
            
            # Find the main component class (not base classes)
            component_classes = []
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    # Skip embedded base classes
                    if node.name not in ['ComposedComponent', 'StandaloneMetricsCollector', 
                                        'StandaloneTracer', 'StandaloneSpan', 'ComponentStatus']:
                        component_classes.append(node)
            
            if not component_classes:
                print("❌ No component class found")
                return False
            
            main_class = component_classes[0]  # Take the first non-base class
            
            # Check for process_item method with real implementation
            process_item_method = None
            for item in main_class.body:
                if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)) and item.name == 'process_item':
                    process_item_method = item
                    break
            
            if not process_item_method:
                print("❌ No process_item method found")
                return False
            
            # Check method body has more than just pass statements
            meaningful_statements = 0
            for stmt in ast.walk(process_item_method):
                if isinstance(stmt, (ast.Return, ast.Assign, ast.AugAssign, ast.Call, ast.If, ast.Try)):
                    meaningful_statements += 1
            
            if meaningful_statements < 2:  # Should have at least a few meaningful operations
                print(f"❌ process_item method too simple: only {meaningful_statements} meaningful statements")
                return False
            
            print(f"✅ Found component class '{main_class.name}' with substantial process_item implementation")
            return True
            
        except Exception as e:
            print(f"❌ Business logic verification failed: {e}")
            return False
    
    def _validate_generated_code(self, code: str, component_type: str, class_name: str) -> None:
        """Validate generated code meets requirements with enhanced checking"""
        
        # Use enhanced AST-based validation first
        self.validate_no_placeholders(code)
        
        # Use new comprehensive functional validation
        if not self._validate_functional_implementation(code):
            raise ComponentGenerationError(
                f"Generated code failed functional validation - contains placeholder patterns or insufficient business logic"
            )
        
        # Run new validation functions
        valid, issues = self.validate_generated_component(code)
        if not valid:
            raise ComponentGenerationError(
                f"Generated component validation failed: {'; '.join(issues)}"
            )
        
        # Run AST validation
        valid, message = self.validate_ast_syntax(code)
        if not valid:
            raise ComponentGenerationError(
                f"AST validation failed: {message}"
            )
        
        # Run import validation
        valid, missing_imports = self.validate_imports(code)
        if not valid:
            raise ComponentGenerationError(
                f"Import validation failed. Missing imports: {', '.join(missing_imports)}"
            )
        
        # Check for FORBIDDEN autocoder_cc imports (allow architectural templates)
        forbidden_patterns = [
            'from autocoder_cc.components import',
            'from autocoder_cc.components.composed_base import ComposedComponent',
            'ComposedComponent'
        ]
        
        # Allowed architectural template imports
        allowed_patterns = [
            'from autocoder_cc.blueprint_language.architectural_templates.',
            'import autocoder_cc.blueprint_language.architectural_templates.'
        ]
        
        # Check for forbidden patterns but allow architectural templates
        import re
        for pattern in forbidden_patterns:
            if pattern in code:
                raise ComponentGenerationError(
                    f"Generated code uses FORBIDDEN pattern: {pattern}\n"
                    f"Component type: {component_type}\n"
                    f"MUST use standalone patterns with embedded base class."
                )
        
        # Check for other autocoder_cc imports that are not architectural templates
        for line in code.split('\n'):
            if ('from autocoder_cc.' in line or 'import autocoder_cc.' in line):
                # Check if it's an allowed architectural template import
                is_allowed = any(allowed_pattern in line for allowed_pattern in allowed_patterns)
                if not is_allowed:
                    raise ComponentGenerationError(
                        f"Generated code uses FORBIDDEN import: {line.strip()}\n"
                        f"Component type: {component_type}\n"
                        f"Only architectural template imports are allowed from autocoder_cc.*"
                    )
        
        # Ensure standalone patterns are present
        required_patterns = [
            'class ComposedComponent:',
            'def get_logger(',
            'ComposedComponent',
            'def process_item(self'
        ]
        
        missing_patterns = []
        for pattern in required_patterns:
            if pattern not in code:
                missing_patterns.append(pattern)
        
        if missing_patterns:
            raise ComponentGenerationError(
                f"Generated code missing required standalone patterns: {missing_patterns}\n"
                f"Component type: {component_type}\n"
                f"MUST inherit from ComposedComponent (embedded) and implement process_item() method."
            )
        
        # Additional placeholder checks
        forbidden_patterns = [
            'return {"value": 42}',
            'return {"test": True}',
            '# TODO',
            'pass  # TODO',
            'raise NotImplementedError',
            'dummy_value',
            'placeholder',
            'FIXME'
        ]
        
        code_lower = code.lower()
        for pattern in forbidden_patterns:
            if pattern.lower() in code_lower:
                raise ComponentGenerationError(
                    f"Generated code contains forbidden placeholder pattern: {pattern}\n"
                    f"Component type: {component_type}\n"
                    f"LLM must generate complete implementations without placeholders."
                )
        
        # Check for required elements
        if class_name not in code:
            raise ComponentGenerationError(
                f"Generated code missing required class: {class_name}"
            )
        
        # Check for required method based on component type
        required_methods = {
            "Source": "process_item",  # Standalone component pattern
            "Transformer": "process_item",  # Standalone component pattern
            "Sink": "process_item",  # Standalone component pattern
            "Model": "process_item",  # Standalone component pattern
            "Store": "process_item",  # Standalone component pattern
            "Accumulator": "process_item",  # Standalone component pattern
            "StreamProcessor": "process_item",  # Standalone component pattern
            "APIEndpoint": "process_item"  # Standalone component pattern
        }
        
        if component_type in required_methods:
            method = required_methods[component_type]
            if f"def {method}" not in code and f"async def {method}" not in code:
                raise ComponentGenerationError(
                    f"Generated {component_type} missing required method: {method}"
                )
        
        # Verify it's valid Python using external compilation
        try:
            import subprocess
            import tempfile
            import os
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as tmp_file:
                tmp_file.write(code.strip())
                tmp_file.flush()
                tmp_filename = tmp_file.name
            
            try:
                result = subprocess.run([
                    'python', '-m', 'py_compile', tmp_filename
                ], capture_output=True, text=True, timeout=10)
                
                if result.returncode != 0:
                    raise ComponentGenerationError(f"Code compilation failed: {result.stderr}")
                    
            finally:
                try:
                    os.unlink(tmp_filename)
                except:
                    pass
                    
        except subprocess.TimeoutExpired:
            raise ComponentGenerationError("Code compilation timeout")
        except subprocess.CalledProcessError as e:
            raise ComponentGenerationError(f"Code compilation subprocess failed: {e}")
        except Exception as e:
            raise ComponentGenerationError(f"Code validation failed: {e}")
    
    def _sanitize_prompt_for_logging(self, prompt: str) -> str:
        """Sanitize prompt for logging by removing sensitive information"""
        import re
        
        # Remove API keys and tokens
        sanitized = re.sub(r'(api[_-]?key|token|secret|password)\s*[=:]\s*[\'"]?[a-zA-Z0-9_-]{10,}[\'"]?', 
                          r'\1=***REDACTED***', prompt, flags=re.IGNORECASE)
        
        # Remove email addresses
        sanitized = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', 
                          '***EMAIL_REDACTED***', sanitized)
        
        # Remove URLs with credentials
        sanitized = re.sub(r'https?://[^:]+:[^@]+@[^/]+', 
                          'https://***CREDENTIALS_REDACTED***@***HOST***', sanitized)
        
        # Remove potential IP addresses
        sanitized = re.sub(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', 
                          '***IP_REDACTED***', sanitized)
        
        # Remove long strings that might be keys/tokens
        sanitized = re.sub(r'[\'"][a-zA-Z0-9+/=]{40,}[\'"]', 
                          '***LONG_TOKEN_REDACTED***', sanitized)
        
        return sanitized

    def validate_component_requirements(self, component_spec: Dict[str, Any]) -> bool:
        """Validate component specification before generation."""
        required_fields = ["name", "type", "inputs", "outputs"]
        
        for field in required_fields:
            if field not in component_spec:
                self.logger.error(f"Missing required field: {field}")
                return False
        
        # Validate component type
        valid_types = ["Source", "Sink", "Controller", "Transformer", "Model", "Store", "APIEndpoint"]
        if component_spec["type"] not in valid_types:
            self.logger.error(f"Invalid component type: {component_spec['type']}")
            return False
        
        return True

    def validate_generated_component(self, code: str) -> tuple[bool, list[str]]:
        """Validate generated standalone component code for common issues."""
        issues = []
        
        # Check for FORBIDDEN imports from autocoder_cc (allow architectural templates)
        forbidden_patterns = [
            "from autocoder_cc.components import",
            "from autocoder_cc.components.composed_base import ComposedComponent",
            "ComposedComponent"
        ]
        
        # Allowed architectural template imports
        allowed_patterns = [
            "from autocoder_cc.blueprint_language.architectural_templates.",
            "import autocoder_cc.blueprint_language.architectural_templates."
        ]
        
        # Check for forbidden patterns but allow architectural templates
        for pattern in forbidden_patterns:
            if pattern in code:
                issues.append(f"FORBIDDEN import found: {pattern} - standalone components must use embedded base classes")
        
        # Check for other autocoder_cc imports that are not architectural templates
        for line in code.split('\n'):
            if ('from autocoder_cc.' in line or 'import autocoder_cc.' in line):
                # Check if it's an allowed architectural template import
                is_allowed = any(allowed_pattern in line for allowed_pattern in allowed_patterns)
                if not is_allowed:
                    issues.append(f"FORBIDDEN import found: {line.strip()} - only architectural template imports are allowed from autocoder_cc.*")
        
        # Check for required standalone patterns
        required_patterns = [
            "class ComposedComponent:",
            "def get_logger(",
            "class StandaloneMetricsCollector:",
            "class StandaloneTracer:"
        ]
        
        for pattern in required_patterns:
            if pattern not in code:
                issues.append(f"Missing required standalone pattern: {pattern}")
        
        # Check that component inherits from ComposedComponent
        if "ComposedComponent)" not in code:
            issues.append("Component must inherit from ComposedComponent")
        
        # Check for blocking async calls in __init__
        if "anyio.run(" in code or "asyncio.run(" in code:
            if "def __init__" in code:
                issues.append("Blocking async call found in __init__ method")
        
        # Check for undefined method references
        try:
            import ast
            tree = ast.parse(code)
            # Add AST validation for method references
        except SyntaxError as e:
            issues.append(f"Syntax error: {e}")
        
        return len(issues) == 0, issues

    def validate_ast_syntax(self, code: str) -> tuple[bool, str]:
        """Validate generated code using AST parsing."""
        try:
            import ast
            tree = ast.parse(code)
            
            # Check for class definitions
            classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
            if not classes:
                return False, "No class definition found"
            
            # Look for the component class (not the base class)
            component_class = None
            for class_node in classes:
                # Skip the embedded base classes
                if class_node.name in ['ComposedComponent', 'StandaloneMetricsCollector', 'StandaloneTracer', 'StandaloneSpan', 'ComponentStatus']:
                    continue
                # This should be the actual component class
                component_class = class_node
                break
            
            if not component_class:
                return False, "No component class found (only base classes)"
            
            # Check for required methods (including async methods) in the component class
            methods = [node.name for node in component_class.body if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef))]
            required_methods = ["__init__", "process_item"]
            
            for method in required_methods:
                if method not in methods:
                    return False, f"Missing required method: {method} in component class {component_class.name}"
            
            return True, "AST validation passed"
            
        except SyntaxError as e:
            return False, f"Syntax error: {e}"

    def validate_imports(self, code: str) -> tuple[bool, list[str]]:
        """Validate that all required standalone imports are present and no forbidden imports exist."""
        # Check for FORBIDDEN imports (allow architectural templates)
        forbidden_patterns = [
            "from autocoder_cc.components import",
            "from autocoder_cc.components.composed_base import ComposedComponent",
            "ComposedComponent"
        ]
        
        # Allowed architectural template imports
        allowed_patterns = [
            "from autocoder_cc.blueprint_language.architectural_templates.",
            "import autocoder_cc.blueprint_language.architectural_templates."
        ]
        
        # Check for forbidden patterns but allow architectural templates
        for pattern in forbidden_patterns:
            if pattern in code:
                return False, [f"FORBIDDEN import found: {pattern}"]
        
        # Check for other autocoder_cc imports that are not architectural templates
        for line in code.split('\n'):
            if ('from autocoder_cc.' in line or 'import autocoder_cc.' in line):
                # Check if it's an allowed architectural template import
                is_allowed = any(allowed_pattern in line for allowed_pattern in allowed_patterns)
                if not is_allowed:
                    return False, [f"FORBIDDEN import found: {line.strip()} - only architectural template imports are allowed"]
        
        # Check for required standalone imports/patterns
        required_patterns = [
            "Dict", "Any", "Optional",
            "logging", "time",
            "ComposedComponent",
            "get_logger"
        ]
        
        missing_imports = []
        for pattern in required_patterns:
            if pattern not in code:
                missing_imports.append(pattern)
        
        return len(missing_imports) == 0, missing_imports